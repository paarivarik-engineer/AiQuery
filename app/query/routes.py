from flask import render_template, redirect, url_for, flash, request, current_app, abort, jsonify
from app.utils.audit_logger import log_audit_event
from app.models import AuditActionType
from flask_login import current_user, login_required
from app import db
from app.query import bp
from app.query.forms import QueryForm
from app.models import Connector
from sqlalchemy import create_engine, text, exc as sqlalchemy_exc, inspect as sqlalchemy_inspect # Added inspect
import numpy as np
import pandas as pd
import os # For reading environment variables
from openai import OpenAI, OpenAIError, Timeout # For OpenRouter API call and error handling
import re # For extracting SQL from LLM response
import logging # Import standard logging
import time # For timing operations

# --- Helper Function for Schema Fetching ---
def get_db_schema(engine):
    """Inspects the database and returns a simplified schema description."""
    inspector = sqlalchemy_inspect(engine)
    schema_info = []
    try:
        # Limit schema fetching for performance/cost if needed, e.g., only specific schemas/tables
        # schema_names = inspector.get_schema_names() # Get all schemas
        # For simplicity, using default schema
        tables = inspector.get_table_names() # Get tables in default schema
        for table_name in tables:
            columns = inspector.get_columns(table_name)
            # Include primary keys and foreign keys if useful for the LLM
            # pk_constraint = inspector.get_pk_constraint(table_name)
            # fk_constraints = inspector.get_foreign_keys(table_name)
            column_details = [f"{col['name']} ({str(col['type'])})" for col in columns] # Ensure type is string
            schema_info.append(f"Table: {table_name}\nColumns: {', '.join(column_details)}")
        return "\n\n".join(schema_info) if schema_info else "No tables found in default schema."
    except Exception as e:
        current_app.logger.error(f"Schema inspection failed: {e}")
        # Return error string if inspection fails, LLM might still work without schema
        return f"Error fetching schema: {e}"

# --- OpenRouter Client Setup ---
# Use environment variables for configuration
openrouter_api_key = os.environ.get("OPENROUTER_API_KEY")
openrouter_model = os.environ.get("OPENROUTER_MODEL", "anthropic/claude-3-haiku") # Default model

client = None
if not openrouter_api_key or openrouter_api_key == 'YOUR_OPENROUTER_API_KEY_HERE':
    logging.getLogger(__name__).warning("OPENROUTER_API_KEY not set or is placeholder. NL query mode will be disabled.")
else:
    try:
        logging.getLogger(__name__).debug(f"Initializing OpenRouter client with key from env: {openrouter_api_key[:4]}...") # Log first 4 chars of key
        # Explicitly pass the key read from os.environ
        client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=openrouter_api_key, # Pass the variable directly
            timeout=30.0, # Add a 30-second timeout for API calls
        )
        logging.getLogger(__name__).debug("Attempting to list models to verify API key...")
        # Test client connectivity
        models = client.models.list()  # This will verify the API key works
        logging.getLogger(__name__).info(f"OpenRouter client initialized successfully for model: {openrouter_model}")
        logging.getLogger(__name__).debug(f"Available models: {[m.id for m in models.data]}")
    except Exception as e:
        logging.getLogger(__name__).error(f"OpenRouter initialization failed: {str(e)}")
        flash(f"OpenRouter initialization failed: {str(e)}", "error")


@bp.route('/', methods=['GET', 'POST'])
@login_required
def query_interface():
    """Query interface with connection verification and NL->SQL."""
    form = QueryForm()
    results = None
    headers = []
    error_message = None
    generated_sql = None # To display the SQL generated by LLM

    if form.validate_on_submit():
        # Begin request logging
        logger = logging.getLogger(__name__)
        logger.info("\n" + "="*80)
        logger.info(f"QUERY REQUEST | User: {current_user.username} (ID: {current_user.id})")
        logger.info("-"*80)
        logger.info("Form inputs:")
        logger.info(f"  Connector ID: {form.connector.data}")
        logger.info(f"  Query Mode: {form.query_mode.data}")
        logger.info(f"  Query: {form.query_input.data}")
        
        connector = db.session.get(Connector, form.connector.data)
        logger.info(f"Connector: {connector.name} (Type: {connector.db_type.value})")
        logger.info(f"Host: {connector.host}:{connector.port}")
        
        # Define query_mode and query_input here to ensure scope
        query_mode = form.query_mode.data
        query_input = form.query_input.data

        # Verify connector ownership
        if not connector or connector.user_id != current_user.id:
            flash('Invalid connector selected.', 'danger')
            return redirect(url_for('query.query_interface'))

        sql_to_execute = None
        try:
            # First test connection (always do this)
            connection_string = connector.get_connection_string()
            test_engine = create_engine(connection_string)
            with test_engine.connect() as conn:
                conn.execute(text("SELECT 1")) # Simple test query

            # Connection successful, proceed based on mode
            if query_mode == 'sql':
                sql_to_execute = query_input
                logger.info(f"Preparing direct SQL query: {sql_to_execute}")
                # Note: Actual execution and logging happen later in the common execution block
            elif query_mode == 'nl':
                logger.info("Processing natural language query...")
                if not client:
                     error_message = "Natural language querying is disabled. Please set OPENROUTER_API_KEY in .env"
                     # flash("Natural language querying is disabled. Please set OPENROUTER_API_KEY in .env", "danger") # REMOVED
                     sql_to_execute = None
                else:
                    try:
                        # 1. Get Schema
                        schema_engine = create_engine(connection_string) # Use separate engine for schema
                        schema_description = get_db_schema(schema_engine)
                        schema_engine.dispose() # Close schema engine connection
                        logger.debug(f"Fetched schema for NL query:\n{schema_description}")

                        if "Error fetching schema" in schema_description:
                             # flash(f"Warning: Could not fetch full schema. {schema_description}", "warning") # REMOVED
                             logger.warning(f"Could not fetch full schema. {schema_description}")
                             # Proceed without schema or with partial schema if possible

                        # 2. Construct Prompt
                        prompt = f"""Given the following database schema:
{schema_description}

Translate this natural language question into a single, executable SQL query: "{query_input}"

Respond ONLY with the SQL query, without any explanation, comments, or markdown formatting."""

                        # 3. Call OpenRouter API
                        llm_start_time = time.time()
                        current_app.logger.info(f"Sending NL query to OpenRouter model: {openrouter_model}")
                        try:
                            completion = client.chat.completions.create(
                                model=openrouter_model,
                                messages=[
                                    {"role": "system", "content": "You are an expert SQL generator."},
                                    {"role": "user", "content": prompt},
                                ],
                                temperature=0.1, # Lower temperature for more deterministic SQL
                                max_tokens=500
                            )
                            llm_end_time = time.time()
                            llm_duration_ms = int((llm_end_time - llm_start_time) * 1000)
                            logger.info(f"LLM call completed in {llm_duration_ms}ms")
                            # Log the entire completion object for debugging
                            logger.debug(f"Raw OpenRouter completion object: {completion}")
                        except Timeout as e: # Use the directly imported Timeout exception
                            llm_end_time = time.time()
                            llm_duration_ms = int((llm_end_time - llm_start_time) * 1000)
                            logger.error(f"OpenRouter API call timed out after {llm_duration_ms}ms: {e}")
                            error_message = "The AI model took too long to respond. Please try again."
                            sql_to_execute = None
                            # Log timeout
                            log_audit_event(current_user.id, AuditActionType.LLM_CALL, {
                                'connector_id': connector.id,
                                'nl_query': query_input,
                                'model': openrouter_model,
                                'error': 'API Timeout',
                                'status': 'failed',
                                'llm_duration_ms': llm_duration_ms
                            })
                            completion = None
                        except OpenAIError as e:
                            llm_end_time = time.time()
                            llm_duration_ms = int((llm_end_time - llm_start_time) * 1000)
                            logger.error(f"OpenRouter API error after {llm_duration_ms}ms: Status Code: {getattr(e, 'status_code', 'N/A')}, Response: {e.response.text if hasattr(e, 'response') and e.response else 'N/A'}")
                            # Check specifically for rate limit error (429)
                            if hasattr(e, 'status_code') and e.status_code == 429:
                                error_message = "Rate limit exceeded for the AI model. Please wait a moment and try again, or try a different model if the issue persists."
                            else:
                                error_message = f"Error communicating with the AI model: {e}"
                            sql_to_execute = None
                            # Log failed LLM call attempt
                            log_audit_event(current_user.id, AuditActionType.LLM_CALL, {
                                'connector_id': connector.id,
                                'nl_query': query_input,
                                'model': openrouter_model,
                                'error': error_message,
                                'status': 'failed',
                                'llm_duration_ms': llm_duration_ms
                            })
                            completion = None # Ensure completion is None on error
                        except Exception as e: # Catch other potential errors during LLM call
                            llm_end_time = time.time()
                            llm_duration_ms = int((llm_end_time - llm_start_time) * 1000)
                            logger.error(f"Error during LLM call after {llm_duration_ms}ms: {e}", exc_info=True)
                            error_message = f"An unexpected error occurred during AI processing: {e}"
                            sql_to_execute = None
                            # Log failed LLM call attempt
                            log_audit_event(current_user.id, AuditActionType.LLM_CALL, {
                                'connector_id': connector.id,
                                'nl_query': query_input,
                                'model': openrouter_model,
                                'error': error_message,
                                'status': 'failed',
                                'llm_duration_ms': llm_duration_ms,
                                'exception_type': type(e).__name__
                            })
                            completion = None # Ensure completion is None on error

                        # Proceed only if LLM call was successful
                        if completion and completion.choices and completion.choices[0].message and completion.choices[0].message.content:
                            generated_sql_raw = completion.choices[0].message.content.strip()
                            logger.info(f"Received SQL content from OpenRouter: {generated_sql_raw}")
                        else:
                            # Error already logged if completion is None due to exception
                            if completion is not None: # Log error only if completion exists but content is bad
                                current_app.logger.error("OpenRouter returned empty or invalid response content.")
                                flash("Failed to get valid SQL from the AI model.", "danger")
                                # Log failed LLM response parsing
                                log_audit_event(current_user.id, AuditActionType.LLM_CALL, {
                                    'connector_id': connector.id,
                                    'nl_query': query_input,
                                    'model': openrouter_model,
                                    'error': 'Invalid or empty response content',
                                    'status': 'failed',
                                    'llm_duration_ms': llm_duration_ms
                                })
                            sql_to_execute = None
                            generated_sql = None # Ensure it's None if invalid
                            generated_sql_raw = None # Ensure raw is also None

                        # Proceed only if we got some SQL
                        if generated_sql_raw:
                            logger.debug("Attempting to extract SQL from LLM response...")
                            # Basic cleanup/extraction (remove potential markdown backticks)
                            match = re.search(r"```(?:sql)?\s*(.*?)\s*```", generated_sql_raw, re.DOTALL | re.IGNORECASE)
                            if match:
                                sql_to_execute = match.group(1).strip()
                            else:
                                 sql_to_execute = generated_sql_raw.strip(';').strip() # Remove trailing semicolon if any
                            
                            generated_sql = sql_to_execute # Store the cleaned SQL for display

                            # Check if sql_to_execute is valid before calling .upper()
                            if sql_to_execute and not sql_to_execute.upper().startswith(("SELECT", "WITH")):
                                 error_message = "Generated query is not a SELECT statement. Execution aborted for safety."
                                 logger.warning(f"Non-SELECT query generated and blocked: {sql_to_execute}")
                                 # Log blocked query attempt
                                 log_audit_event(current_user.id, AuditActionType.QUERY_EXECUTED, {
                                     'connector_id': connector.id,
                                     'nl_query': query_input,
                                     'generated_sql': sql_to_execute,
                                     'error': error_message,
                                     'status': 'blocked',
                                     'mode': query_mode,
                                     'llm_duration_ms': llm_duration_ms
                                 })
                                 sql_to_execute = None # Only execute SELECT for safety
                            elif sql_to_execute:
                                 logger.info(f"Generated SQL ready for execution: {sql_to_execute}")
                            else:
                                 # Handle cases where generated_sql was empty or became empty after stripping
                                 error_message = "AI model did not return a valid SQL query."
                                 logger.warning("Generated SQL was empty or invalid after processing.")
                                 # Log invalid generated SQL
                                 log_audit_event(current_user.id, AuditActionType.LLM_CALL, {
                                     'connector_id': connector.id,
                                     'nl_query': query_input,
                                     'model': openrouter_model,
                                     'raw_response': generated_sql_raw,
                                     'error': 'Generated SQL invalid/empty after processing',
                                     'status': 'failed',
                                     'llm_duration_ms': llm_duration_ms
                                 })
                                 sql_to_execute = None
                        else: # Handle case where generated_sql_raw itself was None from the start
                             # Error should have been logged during LLM call exception handling
                             if not error_message: # If no specific error message set yet
                                 error_message = "AI model failed to generate SQL."
                             sql_to_execute = None

                        # Check if response content exists
                        if completion.choices and completion.choices[0].message and completion.choices[0].message.content:
                            generated_sql = completion.choices[0].message.content.strip()
                            logger.info(f"Received SQL content from OpenRouter: {generated_sql}")
                        else:
                            current_app.logger.error("OpenRouter returned empty or invalid response content.")
                            flash("Failed to get valid SQL from the AI model.", "danger")
                            sql_to_execute = None
                            generated_sql = None # Ensure it's None if invalid

                        # Proceed only if we got some SQL
                        if generated_sql:
                            logger.debug("Attempting to extract SQL from LLM response...")
                            # Basic cleanup/extraction (remove potential markdown backticks)
                            match = re.search(r"```(?:sql)?\s*(.*?)\s*```", generated_sql, re.DOTALL | re.IGNORECASE)
                            if match:
                                sql_to_execute = match.group(1).strip()
                            else:
                                 sql_to_execute = generated_sql.strip(';').strip() # Remove trailing semicolon if any

                            # Check if sql_to_execute is valid before calling .upper()
                            if sql_to_execute and not sql_to_execute.upper().startswith(("SELECT", "WITH")):
                                 error_message = "Generated query is not a SELECT statement. Execution aborted for safety."
                                 # flash("Generated query is not a SELECT statement. Execution aborted for safety.", "warning") # REMOVED
                                 logger.warning(f"Non-SELECT query generated and blocked: {sql_to_execute}")
                                 sql_to_execute = None # Only execute SELECT for safety
                            elif sql_to_execute:
                                 # flash(f"Generated SQL: {sql_to_execute}", "info") # REMOVED Flash message
                                 logger.info(f"Generated SQL ready for execution: {sql_to_execute}")
                            else:
                                 # Handle cases where generated_sql was empty or became empty after stripping
                                 error_message = "AI model did not return a valid SQL query."
                                 # flash("AI model did not return a valid SQL query.", "warning") # REMOVED
                                 logger.warning("Generated SQL was empty or invalid after processing.")
                                 sql_to_execute = None
                        else: # Handle case where generated_sql itself was None from the start
                             error_message = "AI model failed to generate SQL."
                             sql_to_execute = None


                    except OpenAIError as e:
                         logger.error(f"OpenRouter API error: Status Code: {e.status_code}, Response: {e.response.text if e.response else 'N/A'}")
                         # Check specifically for rate limit error (429)
                         if hasattr(e, 'status_code') and e.status_code == 429:
                             error_message = "Rate limit exceeded for the AI model. Please wait a moment and try again, or try a different model if the issue persists."
                             # flash("Rate limit exceeded...", "warning") # REMOVED
                         else:
                             error_message = f"Error communicating with the AI model: {e}"
                             # flash(f"Error communicating with the AI model: {e}", "danger") # REMOVED
                         sql_to_execute = None
                    except Exception as e: # Catch other potential errors during NL processing
                         logger.error(f"Error during NL processing: {e}", exc_info=True)
                         error_message = f"An unexpected error occurred during natural language processing: {e}"
                         # flash(f"An unexpected error occurred...", "danger") # REMOVED
                         sql_to_execute = None
            else: # Invalid query_mode
                error_message = "Invalid query mode selected."
                # flash("Invalid query mode selected.", "danger") # REMOVED
                sql_to_execute = None

            # 4. Execute SQL (if sql_to_execute is valid and no prior critical error)
            if sql_to_execute and not error_message:
                logger.info(f"Executing SQL query:\n{sql_to_execute}")
                execution_engine = create_engine(connection_string)
                sql_start_time = time.time()
                try:
                    with execution_engine.connect() as connection:
                        result = connection.execute(text(sql_to_execute))
                        sql_end_time = time.time()
                        sql_duration_ms = int((sql_end_time - sql_start_time) * 1000)

                        audit_details = {
                            'connector_id': connector.id,
                            'query': sql_to_execute,
                            'sql_duration_ms': sql_duration_ms,
                            'mode': query_mode,
                            'status': 'success'
                        }
                        if query_mode == 'nl':
                            audit_details['nl_query'] = query_input
                            audit_details['llm_duration_ms'] = llm_duration_ms # Add LLM time

                        if result.returns_rows:
                            headers = list(result.keys())
                            # Limit rows fetched for performance if needed, e.g., result.fetchmany(1000)
                            fetched_rows = result.fetchall()
                            results = pd.DataFrame(fetched_rows, columns=headers)
                            row_count = len(results)
                            logger.info(f"Query executed successfully in {sql_duration_ms}ms")
                            logger.info(f"Returned {row_count} rows with columns: {headers}")
                            logger.debug(f"First row sample: {results.iloc[0].to_dict() if row_count > 0 else 'No rows'}")
                            audit_details['row_count'] = row_count
                        else:
                            logger.info(f"Command executed successfully in {sql_duration_ms}ms (no rows returned)")
                            audit_details['row_count'] = 0

                        # Log successful query execution
                        log_audit_event(current_user.id, AuditActionType.QUERY_EXECUTED, audit_details)

                except sqlalchemy_exc.SQLAlchemyError as e: # Catch query execution errors specifically
                    sql_end_time = time.time()
                    sql_duration_ms = int((sql_end_time - sql_start_time) * 1000)
                    error_message = f"Query Execution Error: {getattr(e, 'orig', e)}"
                    logger.error(f"SQLAlchemyError during query execution after {sql_duration_ms}ms: {error_message}")
                    # Log failed query execution
                    audit_details = {
                        'connector_id': connector.id,
                        'query': sql_to_execute,
                        'error': error_message,
                        'status': 'failed',
                        'mode': query_mode,
                        'sql_duration_ms': sql_duration_ms
                    }
                    if query_mode == 'nl':
                         audit_details['nl_query'] = query_input
                         audit_details['llm_duration_ms'] = llm_duration_ms
                    log_audit_event(current_user.id, AuditActionType.QUERY_EXECUTED, audit_details)
                finally:
                    execution_engine.dispose() # Dispose execution engine

                logger.info("-"*80)
                logger.info("Query processing completed")

        except sqlalchemy_exc.OperationalError as e: # Catch connection errors during initial test
            error_message = f"Connection Failed: {getattr(e, 'orig', e)}"
            logger.error(f"Database connection test failed: {error_message}")
            # Log failed connection attempt (no query executed yet)
            log_audit_event(current_user.id, AuditActionType.QUERY_EXECUTED, { # Still log as QUERY_EXECUTED for consistency
                'connector_id': connector.id if connector else None,
                'error': f"Connection Test Failed: {error_message}",
                'status': 'failed',
                'mode': query_mode # Log the intended mode
            })
        except Exception as e: # Catch any other unexpected errors (e.g., during schema fetch before execution)
            # Avoid logging duplicate errors if already handled in LLM block
            if not error_message: 
                error_message = f"An unexpected error occurred: {e}"
                logger.error(f"Unexpected error in query interface: {e}", exc_info=True)
                # Log unexpected error
                log_audit_event(current_user.id, AuditActionType.QUERY_EXECUTED, { # Log as QUERY_EXECUTED
                    'connector_id': connector.id if connector else None,
                    'error': error_message,
                    'status': 'failed',
                    'mode': query_mode,
                    'exception_type': type(e).__name__
                })


    # Form handling for GET requests
    elif request.method == 'GET' and form.connector.choices:
        # Pre-select first connector if available
        if form.connector.choices[0][0] != 0:
             form.connector.data = form.connector.choices[0][0]

    if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
        if error_message:
            return jsonify({'error': error_message})
        elif results is not None:
            # Convert all problematic values (NaN, NaT, etc.) to None
            clean_results = results.replace([np.nan, pd.NA, None], None)
            # Ensure all values are JSON serializable
            serializable_results = []
            for record in clean_results.to_dict('records'):
                serializable_record = {}
                for key, value in record.items():
                    if pd.isna(value) or value is None:
                        serializable_record[key] = None
                    elif isinstance(value, (np.generic, pd.Timestamp)):
                        serializable_record[key] = str(value)
                    else:
                        serializable_record[key] = value
                serializable_results.append(serializable_record)
            
            return jsonify({
                'headers': headers,
                'results': serializable_results,
                'generated_sql': generated_sql
            })
        else:
            return jsonify({'message': 'Query executed successfully'})
    
    return render_template('query/query.html',
                       title='Execute Query',
                       form=form,
                       results=results,
                       headers=headers,
                       row_count=len(results) if results is not None else 0,
                       error_message=error_message,
                       generated_sql=generated_sql)
